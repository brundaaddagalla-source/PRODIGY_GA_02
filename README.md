# PRODIGY_GA_02

Text to Image Generation using Stable Diffusion

This project usees a pre trained generative AI model to generate images from the text prompts given by users. 
It uses Stable Diffusion, an open-source AI model that creates high-quality, unique images from text descriptions (prompts) or other images, using a "latent diffusion" process for efficiency, allowing it to run on consumer hardware

Model Used:
Stable Diffusion v1.5
PyTorch based implementation using the diffusers library

Technologies and Tools
- Python
- Google Colab
- Stable Diffusion
- PyTorch
- Gradio
- NVIDIA Tesla T4 GPU

Features
- Generate images from user prompts
- GPU accelerated interface
- Simple interface
- No need of training the model

User Interface
- Enter a text prompt
- Click the generate button
- View the generated image withing a minute

How to Run 
- Open the notebook in Google Colab
- Enable GPU (Runtime → Change runtime type → GPU)
- Run all cells sequentially
- Modify the dataset or prompts if needed
- Generate and observe text outputs

References
https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5
https://www.geeksforgeeks.org/deep-learning/generate-images-from-text-in-python-stable-diffusion/
https://www.datacamp.com/tutorial/gradio-python-tutorial

Author 
Brunda Addagalla 

This repository is part of the PRODIGY Internship Program.
